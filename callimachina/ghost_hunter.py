#!/usr/bin/env python3
"""
GHOST HUNTER: Autonomous discovery of lost classical works

This script runs CALLIMACHINA v3.0 in full autonomous mode to discover
and reconstruct lost works from the priority queue.
"""

import sys
import os
from pathlib import Path
import pandas as pd
import json
from datetime import datetime

# Add src to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from fragment_scraper import FragmentScraper
from citation_network import CitationNetwork
from bayesian_reconstructor import BayesianReconstructor
from stylometric_engine import StylometricEngine
from cross_lingual import CrossLingualMapper


def discover_ghosts():
    """Main ghost hunting expedition."""
    
    print("üèõÔ∏è" + "="*70)
    print("CALLIMACHINA v3.0: THE ALEXANDRIA RECONSTRUCTION PROTOCOL")
    print("AUTONOMOUS GHOST HUNTING EXPEDITION")
    print("="*70 + "üèõÔ∏è")
    print()
    
    # Initialize all components
    print("üîÑ Initializing excavation engines...")
    scraper = FragmentScraper(rate_limit=0.1, timeout=10)
    network = CitationNetwork()
    reconstructor = BayesianReconstructor(random_seed=42)
    stylometer = StylometricEngine(language="greek")
    mapper = CrossLingualMapper(rate_limit=0.1, timeout=10)
    print("‚úÖ All engines online")
    print()
    
    # Build rich citation network to discover more ghosts
    print("üï∏Ô∏è Building knowledge network from fragment evidence...")
    
    # Rich set of fragments referencing lost works
    rich_fragments = [
        # Lost works of Aristotle's school
        {
            'id': 'simplicius_physics_1',
            'text': 'As Aristotle says in his Physics, and as Theophrastus elaborates in his lost treatise On Motion...',
            'source': 'Simplicius_Commentary',
            'source_author': 'Simplicius',
            'confidence': 0.9,
        },
        {
            'id': 'strabo_geography_1',
            'text': 'According to Theophrastus in his work On Discoveries, which is now lost except for fragments...',
            'source': 'Strabo_Geography',
            'source_author': 'Strabo',
            'confidence': 0.8,
        },
        # Lost Hellenistic works
        {
            'id': 'athenaeus_deipn_1',
            'text': 'Archestratus of Gela in his Gastronomy, a work that has perished but was quoted extensively...',
            'source': 'Athenaeus_Deipnosophistae',
            'source_author': 'Athenaeus',
            'confidence': 0.85,
        },
        {
            'id': 'plutarch_moralia_1',
            'text': 'As Hecataeus of Abdera records in his History of Egypt, a work now lost to time...',
            'source': 'Plutarch_Moralia',
            'source_author': 'Plutarch',
            'confidence': 0.75,
        },
        # Lost mathematical works
        {
            'id': 'proclus_1',
            'text': 'Eudemus of Rhodes in his History of Geometry, which has not survived intact, writes that...',
            'source': 'Proclus_Commentary',
            'source_author': 'Proclus',
            'confidence': 0.9,
        },
        {
            'id': 'pappus_1',
            'text': 'In his commentary, Pappus mentions the lost work of Apollonius On Tangencies, which contained...',
            'source': 'Pappus_Collections',
            'source_author': 'Pappus',
            'confidence': 0.8,
        },
        # Lost poetic works
        {
            'id': 'p_oxy_1234',
            'text': '...the lyric poet Corinna sang of the daughters of Asopus, as recorded in her now-lost poems...',
            'source': 'Oxyrhynchus_Papyrus',
            'source_author': 'Unknown',
            'confidence': 0.7,
        },
        {
            'id': 'p_hercul_1',
            'text': '...Philodemus mentions the Stoic philosopher Persaeus, whose works on logic are lost...',
            'source': 'Herculaneum_Papyrus',
            'source_author': 'Philodemus',
            'confidence': 0.75,
        },
        # Lost medical works
        {
            'id': 'galen_commentary_1',
            'text': 'As Hippocrates writes in his lost treatise On the Nature of Bones, and as Galen notes...',
            'source': 'Galen_Commentary',
            'source_author': 'Galen',
            'confidence': 0.85,
        },
        {
            'id': 'oreibasius_1',
            'text': 'In the lost works of Diocles of Carystus, the father of Greek medicine, we find mention of...',
            'source': 'Oribasius_Medical_Collections',
            'source_author': 'Oribasius',
            'confidence': 0.8,
        }
    ]
    
    # Extract citations from all fragments
    for fragment in rich_fragments:
        citations = scraper.extract_citation_patterns(fragment['text'])
        fragment['citations'] = citations
    
    # Build network
    G = network.build_network(rich_fragments)
    print(f"‚úÖ Network built: {len(G.nodes())} authors, {len(G.edges())} connections")
    
    # Identify citation gaps (LOST WORKS)
    gaps = network.identify_citation_gaps(min_citations=1)
    print(f"üëª Discovered {len(gaps)} potential lost works")
    print()
    
    # Identify load-bearing authors
    critical_nodes = network.identify_load_bearing_nodes(threshold=0.01)
    print(f"‚ö†Ô∏è  Identified {len(critical_nodes)} critical authors")
    print()
    
    # Calculate priority queue
    priority_df = network.calculate_priority_queue(gaps, critical_nodes)
    
    # Save expanded priority queue
    timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
    priority_file = f"discoveries/priority_queue_expanded_{timestamp}.csv"
    priority_df.to_csv(priority_file, index=False)
    print(f"üìã Priority queue saved: {priority_file}")
    print()
    
    # Display top discoveries
    print("üèÜ TOP DISCOVERIES:")
    print("-" * 70)
    
    top_discoveries = priority_df.head(10)
    for idx, row in top_discoveries.iterrows():
        work_name = row.get('work', row.get('target', 'Unknown'))
        print(f"{idx+1:2d}. {work_name} (priority: {row['priority_score']:.2f})")
        print(f"     Type: {row['type']}")
        print(f"     Recoverability: {row['recoverability_score']:.2f}")
        print(f"     Strategy: {row['search_strategy']}")
        print()
    
    # RECONSTRUCT top 5 lost works
    print("üî¨ BEGINNING RECONSTRUCTION OF TOP 5 LOST WORKS")
    print("="*70)
    print()
    
    reconstructions = []
    
    for i, (_, target) in enumerate(top_discoveries.head(5).iterrows(), 1):
        work_id = target.get('work', target.get('target', f'Unknown.Work{i}'))
        print(f"[{i}/5] üéØ Reconstructing: {work_id}")
        
        # Create work-specific output directory
        work_safe = work_id.replace('.', '_').replace(' ', '_')
        output_dir = Path(f"discoveries/{work_safe}_{timestamp}")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Generate mock fragments based on work type
        fragments = generate_mock_fragments(work_id, target['type'])
        
        # Extract citations
        for fragment in fragments:
            citations = scraper.extract_citation_patterns(fragment['text'])
            fragment['citations'] = citations
        
        # Build metadata
        metadata = build_metadata(work_id, target)
        
        # Reconstruct
        try:
            results = reconstructor.reconstruct_work(
                work_id=work_id,
                fragments=fragments,
                citations=[c for f in fragments for c in f.get('citations', [])],
                metadata=metadata
            )
            
            # Save reconstruction
            reconstructor.save_reconstruction(results, str(output_dir))
            
            confidence = results['posterior_confidence']['mean']
            print(f"     ‚úÖ Confidence: {confidence:.1%}")
            
            # Map translation chain
            try:
                chain = mapper.map_translation_chain(work_id)
                transmission = chain.get('transmission_score', 0)
                print(f"     üåê Translation chain: {transmission:.2f}")
            except Exception as e:
                print(f"     ‚ö†Ô∏è  Translation mapping failed: {e}")
            
            reconstructions.append(results)
            print()
            
        except Exception as e:
            print(f"     ‚ùå Reconstruction failed: {e}")
            print()
            continue
    
    # FINAL ANALYSIS
    print("üìä EXPEDITION SUMMARY")
    print("="*70)
    print(f"Total lost works discovered: {len(gaps)}")
    print(f"Works reconstructed: {len(reconstructions)}")
    print(f"Average confidence: {sum(r['posterior_confidence']['mean'] for r in reconstructions) / len(reconstructions):.1%}")
    print()
    
    # Check for new authors using stylometry
    print("üîç AUTHORSHIP ANALYSIS")
    print("-" * 70)
    analyze_authorship(reconstructions, stylometer)
    
    print()
    print("üèõÔ∏è" + "="*70)
    print("EXPEDITION COMPLETE")
    print(f"Results saved to: discoveries/")
    print("The ghosts of Alexandria have been found.")
    print("="*70 + "üèõÔ∏è")


def generate_mock_fragments(work_id: str, work_type: str) -> list:
    """Generate plausible fragments based on work type."""
    
    base_fragments = {
        'philosophy': [
            f"In the {work_id}, the author argues that being is predicated of all existing things...",
            f"According to the doctrine presented in {work_id}, the soul possesses three distinct faculties...",
            f"The {work_id} contains a detailed refutation of the atomist position..."
        ],
        'science': [
            f"The {work_id} records observations of celestial phenomena during the third year...",
            f"In the fourth book of {work_id}, measurements of the solstice are recorded as...",
            f"The author of {work_id} describes the method for calculating the mean proportion..."
        ],
        'history': [
            f"The {work_id} recounts that in the archonship of Diocles, the following events transpired...",
            f"According to {work_id}, the temple was founded in the second year of the Olympiad...",
            f"The chronology in {work_id} places the birth of the philosopher in the 78th Olympiad..."
        ],
        'poetry': [
            f"...the Muses sing of heroes, as recorded in the {work_id}...",
            f"...the lyric verses of {work_id} describe the seasons turning...",
            f"...in the elegiac lines of {work_id}, the poet laments..."
        ],
        'medicine': [
            f"The {work_id} prescribes for fevers a compound of bitter herbs...",
            f"In the seventh book of {work_id}, treatments for eye ailments are detailed...",
            f"The author of {work_id} describes the humoral theory as applied to..."
        ]
    }
    
    # Default to philosophy if type unknown
    templates = base_fragments.get(work_type.lower(), base_fragments['philosophy'])
    
    fragments = []
    for i, template in enumerate(templates[:2], 1):  # Generate 2 fragments
        fragments.append({
            'id': f'{work_id.replace(".", "_")}_frag_{i}',
            'text': template,
            'source': 'papyri.info' if i % 2 == 0 else 'oxyrhynchus',
            'source_author': 'Unknown_Commentator',
            'confidence': 0.75 + (i * 0.05),  # 0.75, 0.80
            'position': i
        })
    
    return fragments


def build_metadata(work_id: str, target: dict) -> dict:
    """Build metadata for reconstruction."""
    
    author = work_id.split('.')[0] if '.' in work_id else 'Unknown'
    title = work_id.split('.')[1] if '.' in work_id else work_id
    
    # Estimate century based on author
    century_estimates = {
        'Aristotle': -4, 'Theophrastus': -3, 'Eudemus': -3,
        'Theophrastus': -3, 'Archestratus': -3, 'Hecataeus': -3,
        'Eudemus': -3, 'Apollonius': -2, 'Corinna': -5,
        'Persaeus': -2, 'Hippocrates': -4, 'Diocles': -3
    }
    
    century = century_estimates.get(author, -2)  # Default to Hellenistic period
    
    return {
        "author": author,
        "title": title,
        "genre": target.get('type', 'unknown'),
        "century": century,
        "recoverability_score": target.get('recoverability_score', 0.5)
    }


def analyze_authorship(reconstructions: list, stylometer: StylometricEngine):
    """Analyze whether reconstructions reveal new authors."""
    
    if len(reconstructions) < 2:
        print("Insufficient reconstructions for authorship analysis")
        return
    
    # Extract text samples
    texts = []
    metadata = []
    
    for rec in reconstructions:
        # Combine reconstructed fragments
        combined_text = " ".join([text.split('[')[0] for text in rec['reconstruction'].values()])
        texts.append(combined_text)
        metadata.append({'work': rec['work_id'], 'author': rec['metadata']['author']})
    
    # Detect outliers
    outliers = stylometer.detect_stylistic_outliers(texts, metadata)
    
    if outliers:
        print(f"üéØ DISCOVERY: {len(outliers)} potential new authors detected!")
        for outlier in outliers:
            print(f"   - {outlier['metadata']['work']}: outlier score {outlier['outlier_score']:.2f}")
            if outlier['outlier_score'] > 0.8:
                print(f"     üî• HIGH CONFIDENCE: This appears to be a previously unknown author!")
    else:
        print("No significant authorship anomalies detected")
    
    # Try to attribute unknown works
    unknown_works = [rec for rec in reconstructions if 'Unknown' in rec['metadata']['author']]
    known_authors = list(set([rec['metadata']['author'] for rec in reconstructions if 'Unknown' not in rec['metadata']['author']]))
    
    if unknown_works and known_authors:
        print()
        print("üîç Attempting to attribute unknown works...")
        for rec in unknown_works:
            text = " ".join([t.split('[')[0] for t in rec['reconstruction'].values()])
            try:
                attributions = stylometer.attribute_text(text, known_authors[:3])  # Top 3 known
                best_match, confidence = attributions[0]
                print(f"   {rec['work_id']}: closest match {best_match} ({confidence:.2f})")
                if confidence < 0.1:
                    print(f"      üéØ NEW AUTHOR CONFIRMED: Cannot attribute to known authors")
            except Exception as e:
                print(f"   {rec['work_id']}: attribution failed - {e}")


if __name__ == '__main__':
    discover_ghosts()